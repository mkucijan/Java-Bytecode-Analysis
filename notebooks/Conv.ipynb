{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "\n",
    "import functools\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load embendings\n",
    "\n",
    "embeddings = np.loadtxt(os.path.join(dir_path,'cache','embeddings.vec'))\n",
    "\n",
    "pickle_in = open('cache/database.dict', 'rb')\n",
    "db = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "\n",
    "pickle_in = open('cache/traindata.list', 'rb')\n",
    "traindata = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "\n",
    "pickle_in = open('cache/data2onehot.dict', 'rb')\n",
    "dictionary = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from JavaClassParser import ByteCode\n",
    "reverse_dictionary = dict(zip(dictionary.values(),dictionary.keys()))\n",
    "X_train=[]\n",
    "Y_train=[]\n",
    "X_train_long=[]\n",
    "Y_train_long=[]\n",
    "X_labels = []\n",
    "Y_labels = []\n",
    "\n",
    "for dclass in db.values():\n",
    "    for method in dclass.values():\n",
    "        instructions = method['x']\n",
    "        labels = method['y']\n",
    "        byteIndex = method['index']\n",
    "        \n",
    "        \n",
    "        #\n",
    "        #seperating by labels\n",
    "\n",
    "        cur_section = []\n",
    "        cur_label = labels[0]\n",
    "        if len(instructions)<100:\n",
    "            X_train.append(instructions)\n",
    "            Y_train.append(labels)\n",
    "        else:\n",
    "            X_train_long.append(instructions)\n",
    "            Y_train_long.append(labels)\n",
    "        for instruction, label in zip(instructions,labels):\n",
    "            if label != cur_label:\n",
    "                X_labels.append(cur_section)\n",
    "                Y_labels.append(cur_label)\n",
    "                cur_section = []\n",
    "                cur_label = label\n",
    "            cur_section.append(dictionary.get(instruction,0))\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "X_train_long = np.array(X_train_long)\n",
    "Y_train_long = np.array(Y_train_long)\n",
    "X_labels = np.array(X_labels)\n",
    "Y_labels = np.array(Y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bits = 16\n",
    "zero_value = 2**(num_bits-1)\n",
    "def gray_code(n):\n",
    "    n -= 1\n",
    "    return format(n^(n >> 1), '0'+str(num_bits)+'b')\n",
    "\n",
    "def bin_code(n):\n",
    "    return format(n, '0'+str(num_bits)+'b')\n",
    "\n",
    "def encode_arg(value):\n",
    "    n=zero_value+value\n",
    "    return np.array(list(map(lambda x: int(x), list(gray_code(n)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_instructions = len(ByteCode.mnemonicMap)\n",
    "encoding_len = num_instructions + num_bits\n",
    "encode_dict = dict( zip(ByteCode.mnemonicMap.keys(),range(num_instructions)) )\n",
    "\n",
    "X_encoded = []\n",
    "Y_encoded = []\n",
    "\n",
    "for x_seq,y_seq in zip(X_train,Y_train):\n",
    "    encoded_x_seq = []\n",
    "    encoded_y_seq = []\n",
    "    for x,y in zip(x_seq, y_seq):\n",
    "        x_vector = np.zeros(encoding_len)\n",
    "        if x in encode_dict:\n",
    "            onehot = np.zeros(num_instructions)\n",
    "            onehot[encode_dict[x]] = 1\n",
    "            x_vector[:num_instructions] = onehot\n",
    "        else:\n",
    "            try:\n",
    "                value=int(x)\n",
    "                x_vector[num_instructions:] = encode_arg(value)\n",
    "            except ValueError as e:\n",
    "                continue\n",
    "        encoded_x_seq.append(x_vector)\n",
    "        encoded_y_seq.append(y)\n",
    "    X_encoded.append(encoded_x_seq)\n",
    "    Y_encoded.append(encoded_y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 100\n",
    "batch_size = 32\n",
    "\n",
    "def batch_iterator(batch_size, seq_len = sequence_length,enc_len = encoding_len, X=X_encoded, Y=Y_encoded):\n",
    "    batch_index = 0\n",
    "    while(True):\n",
    "        current_size = 0\n",
    "        batch_X = np.zeros((batch_size, seq_len, enc_len,1))\n",
    "        batch_Y = np.zeros((batch_size, seq_len))\n",
    "        while(current_size < batch_size):\n",
    "            if batch_index == len(X):\n",
    "                batch_index = 0\n",
    "            if len(X[batch_index]) <= sequence_length:\n",
    "                batch_X[current_size,:len(X[batch_index]),:,0] = np.array(X[batch_index])\n",
    "                batch_Y[current_size,:len(X[batch_index])] = np.array(Y[batch_index])[:,1]\n",
    "                current_size += 1\n",
    "            batch_index += 1\n",
    "            yield batch_X, batch_Y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def doublewrap(function):\n",
    "    \"\"\"\n",
    "    A decorator decorator, allowing to use the decorator to be used without\n",
    "    parentheses if not arguments are provided. All arguments must be optional.\n",
    "    \"\"\"\n",
    "    @functools.wraps(function)\n",
    "    def decorator(*args, **kwargs):\n",
    "        if len(args) == 1 and len(kwargs) == 0 and callable(args[0]):\n",
    "            return function(args[0])\n",
    "        else:\n",
    "            return lambda wrapee: function(wrapee, *args, **kwargs)\n",
    "    return decorator\n",
    "\n",
    "\n",
    "@doublewrap\n",
    "def define_scope(function, scope=None, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    A decorator for functions that define TensorFlow operations. The wrapped\n",
    "    function will only be executed once. Subsequent calls to it will directly\n",
    "    return the result so that operations are added to the graph only once.\n",
    "    The operations added by the function live within a tf.variable_scope(). If\n",
    "    this decorator is used with arguments, they will be forwarded to the\n",
    "    variable scope. The scope name defaults to the name of the wrapped\n",
    "    function.\n",
    "    \"\"\"\n",
    "    attribute = '_cache_' + function.__name__\n",
    "    name = scope or function.__name__\n",
    "    @property\n",
    "    @functools.wraps(function)\n",
    "    def decorator(self):\n",
    "        if not hasattr(self, attribute):\n",
    "            with tf.variable_scope(name, *args, **kwargs):\n",
    "                setattr(self, attribute, function(self))\n",
    "        return getattr(self, attribute)\n",
    "    return decorator\n",
    "\n",
    "\n",
    "class ConvolutionModel:\n",
    "\n",
    "    \n",
    "    def __init__(self, image, label,\n",
    "                 learning_rate=3e-2, \n",
    "                 num_epochs=10,\n",
    "                 weight_decay = 1e-2,\n",
    "                 conv1sz = 4,\n",
    "                 conv2sz = 8,\n",
    "                 fc3sz = 512,\n",
    "                 num_instructions = 100,\n",
    "                 representation_size = encoding_len):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.weight_decay = weight_decay\n",
    "        self.conv1sz = conv1sz\n",
    "        self.conv2sz = conv2sz\n",
    "        self.fc3sz = fc3sz\n",
    "        \n",
    "        self.image = image\n",
    "        self.label = label\n",
    "        \n",
    "        self.num_instructions = num_instructions\n",
    "        self.representation_size = representation_size\n",
    "        \n",
    "        self.prediction\n",
    "        self.optimize\n",
    "        self.error\n",
    "\n",
    "    @define_scope\n",
    "    def prediction(self):\n",
    "        inputs = self.image\n",
    "        weight_decay = self.weight_decay\n",
    "        conv1sz = self.conv1sz\n",
    "        conv2sz = self.conv2sz\n",
    "        fc3sz = self.fc3sz\n",
    "        num_instructions = self.num_instructions\n",
    "        representation_size = self.representation_size\n",
    "        \n",
    "        with tf.contrib.framework.arg_scope([layers.convolution2d],\n",
    "          kernel_size=[2, representation_size], stride=1, padding='VALID', activation_fn=tf.nn.relu,\n",
    "          weights_initializer=layers.variance_scaling_initializer(),\n",
    "          weights_regularizer=layers.l2_regularizer(weight_decay)):\n",
    "\n",
    "            net1 = layers.convolution2d(inputs, conv1sz, scope='conv1_1')\n",
    "        \n",
    "        with tf.contrib.framework.arg_scope([layers.convolution2d],\n",
    "          kernel_size=[2, 1], stride=1, padding='VALID', activation_fn=tf.nn.relu,\n",
    "          weights_initializer=layers.variance_scaling_initializer(),\n",
    "          weights_regularizer=layers.l2_regularizer(weight_decay)):\n",
    "            \n",
    "            net1 = layers.convolution2d(net1, conv2sz, scope='conv2_1')\n",
    "            net1 = layers.max_pool2d(net1, [2,1], representation_size, scope='pool1')\n",
    "            \n",
    "        with tf.contrib.framework.arg_scope([layers.convolution2d],\n",
    "          kernel_size=[3, representation_size], stride=1, padding='VALID', activation_fn=tf.nn.relu,\n",
    "          weights_initializer=layers.variance_scaling_initializer(),\n",
    "          weights_regularizer=layers.l2_regularizer(weight_decay)):\n",
    "            \n",
    "            net2 = layers.convolution2d(inputs, conv1sz, scope='conv1_2')\n",
    "        \n",
    "        with tf.contrib.framework.arg_scope([layers.convolution2d],\n",
    "          kernel_size=[3, 1], stride=1, padding='VALID', activation_fn=tf.nn.relu,\n",
    "          weights_initializer=layers.variance_scaling_initializer(),\n",
    "          weights_regularizer=layers.l2_regularizer(weight_decay)):\n",
    "            \n",
    "            net2 = layers.convolution2d(net2, conv2sz, scope='conv2_2')\n",
    "            net2 = layers.max_pool2d(net2, [2,1], representation_size, scope='pool2')\n",
    "            \n",
    "        with tf.contrib.framework.arg_scope([layers.convolution2d],\n",
    "          kernel_size=[4, representation_size], stride=1, padding='VALID', activation_fn=tf.nn.relu,\n",
    "          weights_initializer=layers.variance_scaling_initializer(),\n",
    "          weights_regularizer=layers.l2_regularizer(weight_decay)):\n",
    "            \n",
    "            net3 = layers.convolution2d(inputs, conv1sz, scope='conv1_3')\n",
    "        \n",
    "        with tf.contrib.framework.arg_scope([layers.convolution2d],\n",
    "          kernel_size=[4, 1], stride=1, padding='VALID', activation_fn=tf.nn.relu,\n",
    "          weights_initializer=layers.variance_scaling_initializer(),\n",
    "          weights_regularizer=layers.l2_regularizer(weight_decay)):\n",
    "            \n",
    "            net3 = layers.convolution2d(net3, conv2sz, scope='conv2_3')\n",
    "            net3 = layers.max_pool2d(net3, [2,1], representation_size, scope='pool3')\n",
    "    \n",
    "        with tf.contrib.framework.arg_scope([layers.convolution2d],\n",
    "          kernel_size=[5, representation_size], stride=1, padding='VALID', activation_fn=tf.nn.relu,\n",
    "          weights_initializer=layers.variance_scaling_initializer(),\n",
    "          weights_regularizer=layers.l2_regularizer(weight_decay)):\n",
    "            \n",
    "            net4 = layers.convolution2d(inputs, conv1sz, scope='conv1_4')\n",
    "        \n",
    "        with tf.contrib.framework.arg_scope([layers.convolution2d],\n",
    "          kernel_size=[5, 1], stride=1, padding='VALID', activation_fn=tf.nn.relu,\n",
    "          weights_initializer=layers.variance_scaling_initializer(),\n",
    "          weights_regularizer=layers.l2_regularizer(weight_decay)):\n",
    "            \n",
    "            net4 = layers.convolution2d(net4, conv2sz, scope='conv2_4')\n",
    "            net4 = layers.max_pool2d(net4, [2,1], representation_size, scope='pool4')\n",
    "        \n",
    "        inputs = [net1, net2, net3, net4]\n",
    "            \n",
    "        with tf.contrib.framework.arg_scope([layers.fully_connected],\n",
    "          activation_fn=tf.nn.relu,\n",
    "          weights_initializer=layers.variance_scaling_initializer(),\n",
    "          weights_regularizer=layers.l2_regularizer(weight_decay)):\n",
    "\n",
    "            inputs = list(map(lambda net: layers.flatten(net), inputs))\n",
    "            net = tf.concat(inputs, axis=1)\n",
    "            net = layers.fully_connected(net, fc3sz, scope='fc3')\n",
    "        \n",
    "        instructions_predict = layers.fully_connected(net, num_instructions, activation_fn=tf.nn.sigmoid, scope='instructions')\n",
    "        return instructions_predict\n",
    "\n",
    "    @define_scope\n",
    "    def optimize(self):\n",
    "        mse = tf.losses.mean_squared_error(self.label, self.prediction, scope ='loss')\n",
    "        optimizer = tf.train.RMSPropOptimizer(self.learning_rate)\n",
    "        return optimizer.minimize(mse)\n",
    "\n",
    "    @define_scope\n",
    "    def error(self):\n",
    "        mistakes = tf.not_equal(\n",
    "            self.label, tf.round(self.prediction) )\n",
    "        return tf.reduce_mean(tf.cast(mistakes, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.placeholder(tf.float32, [None, sequence_length, encoding_len, 1])\n",
    "label = tf.placeholder(tf.float32, [None, sequence_length])\n",
    "model = ConvolutionModel(image, label)\n",
    "batch = batch_iterator(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.212285043128\n",
      "0.232957009011\n",
      "0.23038656039\n",
      "0.223713873304\n",
      "0.231031430341\n",
      "0.211320448215\n",
      "0.230083093149\n",
      "0.227006864115\n",
      "0.225341401887\n",
      "0.237722182415\n",
      "0.222975071875\n",
      "0.229705563693\n",
      "0.21961705174\n",
      "0.223609104575\n",
      "0.237149566606\n",
      "0.213368858291\n",
      "0.231625722323\n",
      "0.220592484836\n",
      "0.22351156068\n",
      "0.229850072774\n",
      "0.217599349446\n",
      "0.229692919104\n",
      "0.218477239579\n",
      "0.227028540508\n",
      "0.237201950631\n",
      "0.228171966076\n",
      "0.23328757215\n",
      "0.221325866959\n",
      "0.227951589606\n",
      "0.229257587338\n",
      "0.229913294504\n",
      "0.244105852096\n",
      "0.211018785942\n",
      "0.233143063364\n",
      "0.229004696388\n",
      "0.223190028517\n",
      "0.231143424347\n",
      "0.210074060742\n",
      "0.229141980646\n",
      "0.226053106765\n",
      "0.226486633053\n",
      "0.237924493478\n",
      "0.222257947705\n",
      "0.232028540595\n",
      "0.222814305712\n",
      "0.222398843998\n",
      "0.240917630343\n",
      "0.216089234515\n",
      "0.232189306241\n",
      "0.219176300995\n",
      "0.224454479615\n",
      "0.227687860898\n",
      "0.215301661558\n",
      "0.227731213641\n",
      "0.217536127216\n",
      "0.226033236288\n",
      "0.234611633024\n",
      "0.228206286481\n",
      "0.23119580919\n",
      "0.216526372089\n",
      "0.230881503713\n",
      "0.230339595725\n",
      "0.226392702092\n",
      "0.244216040563\n",
      "0.214528540424\n",
      "0.231305996726\n",
      "0.230899565735\n",
      "0.224537572592\n",
      "0.23142341\n",
      "0.212033958933\n",
      "0.228446532057\n",
      "0.226091040438\n",
      "0.227416907884\n",
      "0.234595375782\n",
      "0.224813944719\n",
      "0.230379335351\n",
      "0.220335982568\n",
      "0.221681719258\n",
      "0.23774927756\n",
      "0.214362356247\n",
      "0.231293353462\n",
      "0.216584176197\n",
      "0.223885477041\n",
      "0.229850072791\n",
      "0.219425578397\n",
      "0.228311055641\n",
      "0.218708454389\n",
      "0.224745303904\n",
      "0.234291908116\n",
      "0.228769870066\n",
      "0.234123916699\n",
      "0.21614523127\n",
      "0.230426300823\n",
      "0.229317196505\n",
      "0.228236994302\n",
      "0.24576408977\n",
      "0.215373916223\n",
      "0.22975433543\n",
      "0.231286126878\n",
      "0.225010838473\n"
     ]
    }
   ],
   "source": [
    "N=len(X_encoded)\n",
    "num_epochs = 10\n",
    "n_steps = N//batch_size\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for _ in range(num_epochs):\n",
    "    avg_error = 0\n",
    "    for _ in range(n_steps):\n",
    "        images, labels = next(batch)\n",
    "        error = sess.run(model.error, {image: images, label: labels})\n",
    "        avg_error += error\n",
    "    print(avg_error/n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
